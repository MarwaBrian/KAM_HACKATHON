{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load your DataFrames\n",
    "jan2020 = pd.read_csv('./filtered_simba/2020 Jan-June_filtered.csv')\n",
    "feb2021 = pd.read_csv('./filtered_simba/2021 Jan-June_filtered.csv')\n",
    "june22 = pd.read_csv('./filtered_simba/2022 Jan-June_filtered.csv')\n",
    "july22 = pd.read_csv('./filtered_simba/2022 Jul-Dec_filtered.csv')\n",
    "june23 = pd.read_csv('./filtered_simba/2023_filtered.csv')\n",
    "july23 = pd.read_csv('./filtered_simba/2023_filtered.csv')\n",
    "\n",
    "#Prepare sets of columns for comparison\n",
    "cols_jan2020 = set(jan2020.columns)\n",
    "cols_feb2021 = set(feb2021.columns)\n",
    "cols_june22 = set(june22.columns)\n",
    "cols_july22 = set(july22.columns)\n",
    "cols_june23 = set(june23.columns)\n",
    "cols_july23 = set(july23.columns)\n",
    "\n",
    "# List of column sets for easy comparison\n",
    "column_sets = [cols_jan2020, cols_feb2021, cols_june22, cols_july22, cols_june23, cols_july23]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common columns across all DataFrames:\n",
      "{'VEHICLE_TAX', 'PRL', 'CUSTOMSVALUE', 'IMPORT_DUTY', 'COUNTRYOFORIGIN', 'BIF', 'VAT_RATE', 'MONTH_', 'IMPORT_VAT', 'HS_CHAPTER', 'DUTY_RATE', 'TAX_PAYABLE', 'YEAR', 'FOB', 'TAX_REMITTED', 'FOBCURRENCYCODE', 'REGIME', 'COUNTRYOFDESTINATION', 'HSCODE', 'REGDATE', 'QUANTITY', 'CPC', 'PORT_OF_DISCHARGE', 'PDL', 'EXCISE_RATE', 'OTHER_TAX', 'CIF_VALUE', 'ENTRYSTATUS', 'ENTRY_NUMBER', 'ITEM_NO', 'RML', 'EXCISE', 'DESCRIPTION'}\n",
      "\n",
      "DataFrame 1 has no unique columns.\n",
      "\n",
      "DataFrame 2 has no unique columns.\n",
      "\n",
      "DataFrame 3 has no unique columns.\n",
      "\n",
      "DataFrame 4 has no unique columns.\n",
      "\n",
      "DataFrame 5 has no unique columns.\n",
      "\n",
      "DataFrame 6 has no unique columns.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the intersection of all columns (common columns)\n",
    "common_columns = set.intersection(*column_sets)\n",
    "print(f\"Common columns across all DataFrames:\\n{common_columns}\\n\")\n",
    "\n",
    "# Find unique columns in each DataFrame\n",
    "for i, cols in enumerate(column_sets):\n",
    "    unique_cols = cols - common_columns\n",
    "    if unique_cols:\n",
    "        print(f\"Unique columns in DataFrame {i + 1}:\\n{unique_cols}\\n\")\n",
    "    else:\n",
    "        print(f\"DataFrame {i + 1} has no unique columns.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting column 12 in DataFrame 1: expected string or bytes-like object, got 'int'\n",
      "Processed DataFrame 1.\n",
      "Error converting column 12 in DataFrame 2: expected string or bytes-like object, got 'int'\n",
      "Processed DataFrame 2.\n",
      "Error converting column 12 in DataFrame 3: expected string or bytes-like object, got 'int'\n",
      "Processed DataFrame 3.\n",
      "Error converting column 12 in DataFrame 4: expected string or bytes-like object, got 'int'\n",
      "Processed DataFrame 4.\n",
      "Error converting column 12 in DataFrame 5: expected string or bytes-like object, got 'int'\n",
      "Error converting column 28 in DataFrame 5: expected string or bytes-like object, got 'int'\n",
      "Error converting column 29 in DataFrame 5: expected string or bytes-like object, got 'int'\n",
      "Processed DataFrame 5.\n",
      "Error converting column 12 in DataFrame 6: expected string or bytes-like object, got 'int'\n",
      "Error converting column 28 in DataFrame 6: expected string or bytes-like object, got 'int'\n",
      "Error converting column 29 in DataFrame 6: expected string or bytes-like object, got 'int'\n",
      "Processed DataFrame 6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_532183/1903567206.py:29: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:, col_index] = df.iloc[:, col_index].apply(clean_and_convert)\n"
     ]
    }
   ],
   "source": [
    "dataframes = [jan2020, feb2021, june22, july22, june23, july23]\n",
    "\n",
    "# Column indices you want to clean and convert to float\n",
    "columns_of_interest = [9, 10, 12, 22, 23, 24, 25, 28, 29, 32]\n",
    "\n",
    "# Function to clean and convert data to float using regular expressions\n",
    "def clean_and_convert(value):\n",
    "    if isinstance(value, float):  # If it's already a float, return it as is\n",
    "        return value\n",
    "    # Remove any non-numeric characters except for '.' (for decimals)\n",
    "    cleaned_value = re.sub(r'[^\\d.]', '', value)\n",
    "    \n",
    "    # Remove commas (if they exist after numbers)\n",
    "    cleaned_value = cleaned_value.replace(',', '')\n",
    "\n",
    "    # Convert to float if possible, else return NaN\n",
    "    try:\n",
    "        return float(cleaned_value)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "# Loop through each DataFrame and clean/convert the specified columns\n",
    "for i, df in enumerate(dataframes):\n",
    "    for col_index in columns_of_interest:\n",
    "        if col_index < df.shape[1]:  # Check if column index is within bounds\n",
    "            if not pd.api.types.is_float_dtype(df.iloc[:, col_index]):  # Check if the column is not already float\n",
    "                try:\n",
    "                    # Apply the cleaning and conversion function\n",
    "                    df.iloc[:, col_index] = df.iloc[:, col_index].apply(clean_and_convert)\n",
    "                except Exception as e:\n",
    "                    # Print the error, DataFrame index, and column index\n",
    "                    print(f\"Error converting column {col_index} in DataFrame {i+1}: {e}\")\n",
    "        else:\n",
    "            print(f\"Column {col_index} is out-of-bounds in DataFrame {i+1}.\")\n",
    "    print(f\"Processed DataFrame {i+1}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame 1 info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3772 entries, 0 to 3771\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   COUNTRYOFDESTINATION  0 non-null      float64\n",
      " 1   PORT_OF_DISCHARGE     0 non-null      float64\n",
      " 2   HSCODE                3772 non-null   int64  \n",
      " 3   DUTY_RATE             2594 non-null   float64\n",
      " 4   EXCISE_RATE           2594 non-null   float64\n",
      " 5   VAT_RATE              2594 non-null   float64\n",
      " 6   BIF                   506 non-null    float64\n",
      " 7   PRL                   2594 non-null   float64\n",
      " 8   PDL                   2594 non-null   float64\n",
      " 9   TAX_REMITTED          2258 non-null   float64\n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 294.8 KB\n",
      "\n",
      "DataFrame 2 info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2555 entries, 0 to 2554\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   COUNTRYOFDESTINATION  0 non-null      float64\n",
      " 1   PORT_OF_DISCHARGE     0 non-null      float64\n",
      " 2   HSCODE                2555 non-null   int64  \n",
      " 3   DUTY_RATE             2538 non-null   float64\n",
      " 4   EXCISE_RATE           2538 non-null   float64\n",
      " 5   VAT_RATE              2538 non-null   float64\n",
      " 6   BIF                   458 non-null    float64\n",
      " 7   PRL                   2538 non-null   float64\n",
      " 8   PDL                   2538 non-null   float64\n",
      " 9   TAX_REMITTED          2230 non-null   float64\n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 199.7 KB\n",
      "\n",
      "DataFrame 3 info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 233 entries, 0 to 232\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   COUNTRYOFDESTINATION  0 non-null      float64\n",
      " 1   PORT_OF_DISCHARGE     0 non-null      float64\n",
      " 2   HSCODE                233 non-null    int64  \n",
      " 3   DUTY_RATE             224 non-null    float64\n",
      " 4   EXCISE_RATE           224 non-null    float64\n",
      " 5   VAT_RATE              224 non-null    float64\n",
      " 6   BIF                   54 non-null     float64\n",
      " 7   PRL                   224 non-null    float64\n",
      " 8   PDL                   224 non-null    float64\n",
      " 9   TAX_REMITTED          162 non-null    float64\n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 18.3 KB\n",
      "\n",
      "DataFrame 4 info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15 entries, 0 to 14\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   COUNTRYOFDESTINATION  0 non-null      float64\n",
      " 1   PORT_OF_DISCHARGE     0 non-null      float64\n",
      " 2   HSCODE                15 non-null     int64  \n",
      " 3   DUTY_RATE             9 non-null      float64\n",
      " 4   EXCISE_RATE           9 non-null      float64\n",
      " 5   VAT_RATE              9 non-null      float64\n",
      " 6   BIF                   3 non-null      float64\n",
      " 7   PRL                   9 non-null      float64\n",
      " 8   PDL                   9 non-null      float64\n",
      " 9   TAX_REMITTED          10 non-null     float64\n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 1.3 KB\n",
      "\n",
      "DataFrame 5 info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   COUNTRYOFDESTINATION  0 non-null      float64\n",
      " 1   PORT_OF_DISCHARGE     0 non-null      float64\n",
      " 2   HSCODE                1 non-null      int64  \n",
      " 3   DUTY_RATE             1 non-null      float64\n",
      " 4   EXCISE_RATE           1 non-null      float64\n",
      " 5   VAT_RATE              1 non-null      float64\n",
      " 6   BIF                   0 non-null      float64\n",
      " 7   PRL                   1 non-null      int64  \n",
      " 8   PDL                   1 non-null      int64  \n",
      " 9   TAX_REMITTED          1 non-null      float64\n",
      "dtypes: float64(7), int64(3)\n",
      "memory usage: 212.0 bytes\n",
      "\n",
      "DataFrame 6 info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   COUNTRYOFDESTINATION  0 non-null      float64\n",
      " 1   PORT_OF_DISCHARGE     0 non-null      float64\n",
      " 2   HSCODE                1 non-null      int64  \n",
      " 3   DUTY_RATE             1 non-null      float64\n",
      " 4   EXCISE_RATE           1 non-null      float64\n",
      " 5   VAT_RATE              1 non-null      float64\n",
      " 6   BIF                   0 non-null      float64\n",
      " 7   PRL                   1 non-null      int64  \n",
      " 8   PDL                   1 non-null      int64  \n",
      " 9   TAX_REMITTED          1 non-null      float64\n",
      "dtypes: float64(7), int64(3)\n",
      "memory usage: 212.0 bytes\n"
     ]
    }
   ],
   "source": [
    "# Loop through each DataFrame to inspect the data types of the specified columns\n",
    "for i, df in enumerate(dataframes):\n",
    "    print(f\"\\nDataFrame {i+1} info:\")\n",
    "    df.iloc[:, columns_of_interest].info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common columns across all DataFrames:\n",
      "{'VEHICLE_TAX', 'PRL', 'CUSTOMSVALUE', 'IMPORT_DUTY', 'COUNTRYOFORIGIN', 'BIF', 'VAT_RATE', 'MONTH_', 'IMPORT_VAT', 'HS_CHAPTER', 'DUTY_RATE', 'TAX_PAYABLE', 'YEAR', 'FOB', 'TAX_REMITTED', 'FOBCURRENCYCODE', 'REGIME', 'COUNTRYOFDESTINATION', 'HSCODE', 'REGDATE', 'QUANTITY', 'CPC', 'PORT_OF_DISCHARGE', 'PDL', 'EXCISE_RATE', 'OTHER_TAX', 'CIF_VALUE', 'ENTRYSTATUS', 'ENTRY_NUMBER', 'ITEM_NO', 'RML', 'EXCISE', 'DESCRIPTION'}\n",
      "\n",
      "DataFrame 1 has no unique columns.\n",
      "\n",
      "DataFrame 2 has no unique columns.\n",
      "\n",
      "DataFrame 3 has no unique columns.\n",
      "\n",
      "DataFrame 4 has no unique columns.\n",
      "\n",
      "DataFrame 5 has no unique columns.\n",
      "\n",
      "DataFrame 6 has no unique columns.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract columns from each DataFrame\n",
    "cols_jan2020 = set(jan2020.columns)\n",
    "cols_feb2021 = set(feb2021.columns)\n",
    "cols_june22 = set(june22.columns)\n",
    "cols_july22 = set(july22.columns)\n",
    "cols_june23 = set(june23.columns)\n",
    "cols_july23 = set(july23.columns)\n",
    "\n",
    "# List of column sets for easy comparison\n",
    "column_sets = [cols_jan2020, cols_feb2021, cols_june22, cols_july22, cols_june23, cols_july23]\n",
    "\n",
    "# Find the intersection of all columns (common columns)\n",
    "common_columns = set.intersection(*column_sets)\n",
    "print(f\"Common columns across all DataFrames:\\n{common_columns}\\n\")\n",
    "\n",
    "# Find unique columns in each DataFrame\n",
    "for i, cols in enumerate(column_sets):\n",
    "    unique_cols = cols - common_columns\n",
    "    if unique_cols:\n",
    "        print(f\"Unique columns in DataFrame {i + 1}:\\n{unique_cols}\\n\")\n",
    "    else:\n",
    "        print(f\"DataFrame {i + 1} has no unique columns.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df = pd.concat([jan2020, feb2021, june22, july22, june23, july23], ignore_index=True)\n",
    "\n",
    "# # Save the combined DataFrame to a CSV file\n",
    "# combined_df.to_csv('comb_icms.csv', index=False)\n",
    "\n",
    "# print(\"Combined DataFrame has been saved as 'comb_icms.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simbjan20 = pd.read_csv('./filtered_simba/2020 Jan-June_filtered.csv')\n",
    "# simbjuly20 = pd.read_csv('./filtered_simba/2020 Jul-Dec_filtered.csv')\n",
    "# simbjan21 = pd.read_csv('./filtered_simba/2021 Jan-June_filtered.csv')\n",
    "# simbjuly21 = pd.read_csv('./filtered_simba/2021 Jul-Dec_filtered.csv')\n",
    "# simbjan22 = pd.read_csv('./filtered_simba/2022 Jan-June_filtered.csv')\n",
    "# simbjuly22 = pd.read_csv('./filtered_simba/2022 Jul-Dec_filtered.csv')\n",
    "# simb23 = pd.read_csv('./filtered_simba/2023_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract columns from each DataFrame\n",
    "# cols_simbjan20 = set(simbjan20.columns)\n",
    "# cols_simbjuly20 = set(simbjuly20.columns)\n",
    "# cols_simbjan21 = set(simbjan21.columns)\n",
    "# cols_simbjuly21 = set(simbjuly21.columns)\n",
    "# cols_simbjan22 = set(simbjan22.columns)\n",
    "# cols_simbjuly22 = set(simbjuly22.columns)\n",
    "# cols_simb23 = set(simb23.columns)\n",
    "\n",
    "# # List of column sets for easy comparison\n",
    "# column_sets = [cols_simbjan20, cols_simbjuly20, cols_simbjan21, cols_simbjuly21, cols_simbjan22, cols_simbjuly22, cols_simb23]\n",
    "\n",
    "# # Find the intersection of all columns (common columns)\n",
    "# common_columns = set.intersection(*column_sets)\n",
    "# print(f\"Common columns across all Simba DataFrames:\\n{common_columns}\\n\")\n",
    "\n",
    "# # Find unique columns in each DataFrame\n",
    "# for i, cols in enumerate(column_sets):\n",
    "#     unique_cols = cols - common_columns\n",
    "#     if unique_cols:\n",
    "#         print(f\"Unique columns in Simba DataFrame {i + 1}:\\n{unique_cols}\\n\")\n",
    "#     else:\n",
    "#         print(f\"Simba DataFrame {i + 1} has no unique columns.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If all columns are the same, combine the DataFrames\n",
    "# if all(cols == cols_simbjan20 for cols in column_sets):\n",
    "#     combined_simba_df = pd.concat([simbjan20, simbjuly20, simbjan21, simbjuly21, simbjan22, simbjuly22, simb23], ignore_index=True)\n",
    "#     print(\"All columns are the same. DataFrames combined.\")\n",
    "# else:\n",
    "#     print(\"Columns are not the same. Cannot combine DataFrames directly.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the combined DataFrame to a CSV file if they were combined\n",
    "# if 'combined_simba_df' in locals():\n",
    "#     combined_simba_df.to_csv('./final_data/comb_simba.csv', index=False)\n",
    "#     print(\"Combined Simba DataFrame has been saved as 'comb_simba.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the datasets\n",
    "# icms = pd.read_csv('./final_data/comb_icms.csv')\n",
    "simba = pd.read_csv('./final_data/comb_simba.csv')\n",
    "exports = pd.read_csv('./final_data/dom_exports.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18563 entries, 0 to 18562\n",
      "Data columns (total 34 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   YEAR                    18563 non-null  int64 \n",
      " 1   MONTH                   18563 non-null  object\n",
      " 2   ENTRY_NUMBER            18563 non-null  object\n",
      " 3   VERSION                 18563 non-null  int64 \n",
      " 4   ITEM_NUM                18563 non-null  int64 \n",
      " 5   ENTRYSTATUS             18563 non-null  object\n",
      " 6   REG_DATE                18563 non-null  object\n",
      " 7   REGIME                  18563 non-null  object\n",
      " 8   CPC                     18563 non-null  object\n",
      " 9   QUANTITY                18563 non-null  object\n",
      " 10  FOB_VALUE               18563 non-null  object\n",
      " 11  CURRENCY                18563 non-null  object\n",
      " 12  ENTRY_CUSTOM_VALUE      18563 non-null  object\n",
      " 13  HS_CHAPTER              18563 non-null  int64 \n",
      " 14  HSCODE                  18563 non-null  int64 \n",
      " 15  GOOD_DESCRIPTION        18563 non-null  object\n",
      " 16  ORIGIN_COUNTRY_CODE     18563 non-null  object\n",
      " 17  ORIGIN_COUNTRY_NAME     18563 non-null  object\n",
      " 18  COUNTRY_OF_DESTINATION  18561 non-null  object\n",
      " 19  COD_NAME                18561 non-null  object\n",
      " 20  STATION                 18563 non-null  object\n",
      " 21  PLACE_OF_DISCHARGE      18563 non-null  object\n",
      " 22  TOTAL_TAX_PAYABLE       18563 non-null  object\n",
      " 23  TOTAL_TAX_PAID          18563 non-null  object\n",
      " 24  IMPORT_DUTY             18563 non-null  object\n",
      " 25  IMPORT_VAT              18563 non-null  object\n",
      " 26  EXCISE                  18563 non-null  int64 \n",
      " 27  EXPORT_DUTY             18563 non-null  int64 \n",
      " 28  IDF                     18563 non-null  object\n",
      " 29  RDL                     18563 non-null  object\n",
      " 30  RML                     18563 non-null  int64 \n",
      " 31  PRL                     18563 non-null  int64 \n",
      " 32  MSS                     18563 non-null  object\n",
      " 33  OTHER_TAX               18563 non-null  object\n",
      "dtypes: int64(9), object(25)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# icms.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_columns = {\n",
    "    'year': 'year',\n",
    "    'month': 'month',\n",
    "    'month_': 'month',\n",
    "    'entry_number': 'entry_number',\n",
    "    'version': 'version',\n",
    "    'item_no': 'item_no',\n",
    "    'item_num': 'item_no',\n",
    "    'entrystatus': 'entrystatus',\n",
    "    'regdate': 'regdate',\n",
    "    'reg_date': 'regdate',\n",
    "    'regime': 'regime',\n",
    "    'cpc': 'cpc',\n",
    "    'countryoforigin': 'countryoforigin',\n",
    "    'origin_country_code': 'countryoforigin',\n",
    "    'origin_country_name': 'origin_country_name',\n",
    "    'countryofdestination': 'countryofdestination',\n",
    "    'country_of_destination': 'countryofdestination',\n",
    "    'port_of_discharge': 'port_of_discharge',\n",
    "    'place_of_discharge': 'port_of_discharge',\n",
    "    'hs_chapter': 'hs_chapter',\n",
    "    'hscode': 'hscode',\n",
    "    'description': 'description',\n",
    "    'good_description': 'description',\n",
    "    'quantity': 'quantity',\n",
    "    'fob': 'fob_value',\n",
    "    'fob_value': 'fob_value',\n",
    "    'fobcurrencycode': 'currency',\n",
    "    'currency': 'currency',\n",
    "    'customsvalue': 'entry_custom_value',\n",
    "    'entry_custom_value': 'entry_custom_value',\n",
    "    'import_duty': 'import_duty',\n",
    "    'import_vat': 'import_vat',\n",
    "    'excise': 'excise',\n",
    "    'vat_rate': 'vat_rate',\n",
    "    'excise_rate': 'excise_rate',\n",
    "    'duty_rate': 'duty_rate',\n",
    "    'tax_payable': 'total_tax_payable',\n",
    "    'total_tax_payable': 'total_tax_payable',\n",
    "    'tax_remitted': 'total_tax_paid',\n",
    "    'total_tax_paid': 'total_tax_paid',\n",
    "    'rml': 'rml',\n",
    "    'prl': 'prl',\n",
    "    'other_tax': 'other_tax',\n",
    "}\n",
    "\n",
    "# Function to rename columns\n",
    "def rename(df, col_map):\n",
    "    # Lowercase the columns in the DataFrame\n",
    "    df.columns = df.columns.str.lower().str.strip()\n",
    "    # Rename the columns using the mapping dictionary\n",
    "    df.rename(columns=col_map, inplace=True)\n",
    "    return df\n",
    "\n",
    "copy_simba = simba.copy()\n",
    "# copy_icms = filtered_icms.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports Data\n",
    "Lets begin with imports data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12656 entries, 0 to 12655\n",
      "Data columns (total 33 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   year                  12656 non-null  int64  \n",
      " 1   month_                12656 non-null  object \n",
      " 2   entry_number          12656 non-null  object \n",
      " 3   entrystatus           12656 non-null  object \n",
      " 4   item_no               12656 non-null  int64  \n",
      " 5   regdate               10335 non-null  object \n",
      " 6   regime                12656 non-null  object \n",
      " 7   cpc                   12656 non-null  object \n",
      " 8   countryoforigin       12656 non-null  object \n",
      " 9   countryofdestination  3578 non-null   object \n",
      " 10  port_of_discharge     12656 non-null  object \n",
      " 11  hs_chapter            12656 non-null  int64  \n",
      " 12  hscode                12656 non-null  int64  \n",
      " 13  description           12656 non-null  object \n",
      " 14  quantity              12656 non-null  object \n",
      " 15  fob                   12656 non-null  object \n",
      " 16  fobcurrencycode       10782 non-null  object \n",
      " 17  cif_value             12656 non-null  object \n",
      " 18  customsvalue          12656 non-null  object \n",
      " 19  import_duty           10462 non-null  object \n",
      " 20  excise                10462 non-null  float64\n",
      " 21  import_vat            10462 non-null  object \n",
      " 22  duty_rate             10462 non-null  float64\n",
      " 23  excise_rate           10462 non-null  float64\n",
      " 24  vat_rate              10462 non-null  float64\n",
      " 25  bif                   507 non-null    float64\n",
      " 26  vehicle_tax           10462 non-null  float64\n",
      " 27  rml                   10462 non-null  float64\n",
      " 28  prl                   10462 non-null  float64\n",
      " 29  pdl                   10462 non-null  float64\n",
      " 30  other_tax             10462 non-null  float64\n",
      " 31  tax_payable           5366 non-null   float64\n",
      " 32  tax_remitted          2291 non-null   float64\n",
      "dtypes: float64(12), int64(4), object(17)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# copy_simba[copy_simba['FOB'].apply(clean_and_convert)]\n",
    "gp_simba = pd.read_csv('./final_data/cleaned_comb_simba.csv')\n",
    "\n",
    "gp_simba.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
